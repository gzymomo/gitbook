[JavaCV入门指南：序章](http://www.yanzuoguang.com/article/704)

## 一、老生常谈

javaCV能做什么，既然是"CV"大法，那自然是计算机视觉领域的库，诸如音视频、流媒体、图像处理、深度学习、机器学习、人工智能等等等（现在流行后面这三个，写上去应该能唬住不少人，deeplearning晓得不，里面一堆的javaCV库没发现吗）。

## 二、入门基础

以上全是些空话，我们无非就是要用javaCV采集视频和音频，给这些音视频编解码，然后是用什么封装格式封装这些音视频数据，以及用什么协议传输，可能还要对视频里的图像进一步进行处理（这个属于图像处理范畴），流程大致如此（音频方面了解不多，大家见谅）：

```shell
拉流（采集）--->图像像素数据/音频数据<---->编/解码 <---->音/视频帧<---->解封装/封装---->推流
```

举例：编解码过程（以hevc编码的rtsp转rtmp/flv为例，无音频数据）：

```shell
rtsp流---拉流解复用--->h265(hevc)---解码--->yuv像素数据---编码--->h264---封装推流--->rtmp/flv
```

### 1、图像像素格式与图片封装格式

图像像素格式（简称像素格式），一般指的是没有经过编码的按照原始像素排列的数据。

举个栗子，一个完整图像的像素排列一般是这样的（以4*4像素的rgb像素格式为例）：

```shell
rgbrgbrgbrgb
rgbrgbrgbrgb
rgbrgbrgbrgb
rgbrgbrgbrgb
```

当然我们存储的时候一般使用一维数组来存这些数据，所以排列顺序就变成这样：rgbrgbrgbrgb.......以此类推。

图片封装格式指的我们日常见到的png，jpg，bmp，gif等等图片格式。其中bmp是无损格式且不压缩，里面的数据格式就是图片头信息加上rgb排列的像素数据；png是无损压缩格式；jpg/gif等都是有损压缩格式。压缩图片可以有效节省更多的硬盘空间。

## 2、图像？视频帧？傻傻分不清楚

图像像素数据指的是yuv、rgb，rbga，bgr，gbra等图像像素格式，经过编码后才是视频帧。比如我们常见的h264编码，编码其实就是对图像像素数据的压缩，（以rgb为例，假如当前图像像素尺寸为1920*1080，，每种颜色用一个字节表示，也就是说每个像素点有红绿蓝三色共3字节，图像有1920*1080个像素点，也就是说这张图像大小为1920*1080*3字节，显然数据太大了），可以这样理解，h264编码本质上就是一种图像数据压缩算法。

- 补充：视频帧中常常提到的I帧，B帧和P帧指的是什么？i帧也叫关键帧，实际上就是一张完整的静态图像，而B帧和P帧只是用来记录画面的运动矢量等非图像数据，B/P帧都需要依赖i帧才能够正确解码出完整图像（有损的图像画面）。在实际应用中各种视频源中很少使用B帧，原因是虽然使用大量B帧可以提高压缩率，但也会消耗更多的硬件性能，所以大多数情况下的视频源都以i帧（关键帧）和大量P帧为主。
- 另外在直播应用中i帧间隔会很低，这样能够更快的显示首帧画面（B/P帧需要i帧才能够解码），但是这样也增加了传输的数据量，因为一个i帧通常会很大。

## 3、编码？封装？傻傻分不清楚

编码上面已经讲了，是一种压缩算法；那么封装格式又是什么呢，封装格式就是我们日常见到的视频文件了，比如mp4，avi，mkv，flv等等等，按照每种封装格式的规范把视频帧和音频按照一定顺序存起来就成我们日常看到的视频文件了，这些封装格式一般都会包含一些头/尾标识和一些视频描述信息，这样播放器读取视频文件的时候就知道该怎么播放这些视频文件了（可以把封装格式理解成收纳箱，上面贴着小纸条说明里面放了哪些东西）。

压缩图片格式也可以参考视频编码格式，原理都一样，都是对图像数据做有损/无损压缩。

- 什么是转封装？为什么转封装比转码消耗更少？为什么转封装无法改动视频尺寸？
- 先举个栗子：假设视频格式(mp4,flv,avi等)是盒子，里面的视频编码数据(h264,hevc)是苹果，我们把这个苹果从盒子里取出来放到另一个盒子里，盒子是变了，苹果是没有变动的，因此视频相关的尺寸数据是没有改动的，这个就是转封装的概念。
- 有了上面这个例子，我们可以把“转码”理解为：把这个盒子里的苹果(hevc)拿出来削皮切块后再加工成樱桃(h264)后再装到另一个盒子里，多了一步对苹果(hevc)转换为樱桃(h264)的操作，自然比直接把苹果拿到另一个盒子（转封装）要消耗更多机器性能。

## 4、音/视频源

音/视频源可以是视频文件、音频文件，流媒体源，设备等等。

比如我们要看电脑或手机摄像头视频，就得采集设备的图像数据（从源设备采集到的是像素数据，一般是bgr或者rgb像素数据）如果是某些厂商的商用摄像机，可能会支持rtsp/rtmp协议，要采集声音呢，就得采集录音/话筒设备里面的数据（一般是pcm采样数据）。

## 5、流媒体协议

rtsp协议栈，rtmp协议栈，hls，http-flv（理论上讲这个flv不能算是流媒体协议，它只是个无限大的flv文件）等等。

例如rtmp，对编码后的音视频帧，要对其进行封装成flv进行传输。

补充：说到底这些协议原理上依然是建立在tcp/udp基础上的应用层传输协议。

## 6、流媒体服务

支持音视频存储分发的服务都可以叫流媒体服务。

比如常见的srs（开源的rtmp流媒体服务，当然它支持rtmp/hls/http-flv的分发）和nginx（通过安装模块可以支持rtmp，hls，http-flv分发），除此之外的收费的和一些不太友好的开源流媒体服务就不一一介绍了。

鉴于很多小伙伴还是比较混乱，为了方便理解，放一张总的音视频像素、编码、格式和协议及图片知识概念关系图：

![1](http://www.yanzuoguang.com/upload/2020/07/sflu4ull4mguuqhauhp7ibefc2.png)